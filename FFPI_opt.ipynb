{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated FPPI: 0.3\n",
      "FPPI = 0.300 [0.004 - 0.326]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "gt_base = 'D:/lunit/data/img/gt_opt/respiratory'\n",
    "base = 'D:/lunit/data/img/ai_json(opt)/respiratory'\n",
    "ai_mask_list = os.listdir(base)\n",
    "sum_image = len(ai_mask_list)\n",
    "\n",
    "fppi_cnt = 0\n",
    "gt_ims= []\n",
    "ai_ims = []\n",
    "for index, ai_mask in enumerate(sorted(ai_mask_list)):\n",
    "    # if index==10:\n",
    "    #     break\n",
    "\n",
    "    gt_file = '{}_gt.png'.format(ai_mask.split('_cutoff')[0])\n",
    "    gt_im = cv2.imread(os.path.join(gt_base, gt_file), cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "#     gt_ims.append(gt_im)\n",
    "    w,h=gt_im.shape\n",
    "#     print(h,w)\n",
    "#     print(\"started reading gt file: {}\".format(gt_file))\n",
    "\n",
    "    im = cv2.imread(os.path.join(base, ai_mask))\n",
    "    im = cv2.resize(im, (h,w),interpolation=cv2.INTER_NEAREST)\n",
    "#     ai_ims.append(im)\n",
    "    imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "    ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     print(gt_im.shape, im.shape)\n",
    "    if gt_im.sum() == 0: # normal\n",
    "        fppi_cnt += len(ai_contours)\n",
    "\n",
    "    else:\n",
    "        for ai_contour in ai_contours:\n",
    "            _image = np.zeros_like(gt_im)\n",
    "            _image = cv2.drawContours(_image, [ai_contour], 0, color=255, thickness=-1)\n",
    "            if _image[gt_im>0].sum() == 0:\n",
    "                fppi_cnt += 1\n",
    "#     print(\"intermediate sum ffpi cnt: {}\".format(fppi_cnt))\n",
    "\n",
    "\n",
    "\n",
    "fppi = fppi_cnt/sum_image\n",
    "print('Calculated FPPI: {}'.format(fppi))\n",
    "\n",
    "# labels = ground truth label list\n",
    "# lables_pred = prediction probability\n",
    "\n",
    "n_bootstraps = 10\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for m in range(n_bootstraps):\n",
    "    fppi_cnt = 0\n",
    "\n",
    "#     y_true = np.array(gt_ims)\n",
    "#     y_pred = np.array(ai_ims)\n",
    "    ai_mask_list = np.array(ai_mask_list)\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(ai_mask_list), len(ai_mask_list))\n",
    "#     if len(np.unique(y_true[indices])) < 2:\n",
    "#         # We need at least one positive and one negative sample for ROC AUC\n",
    "#         # to be defined: reject the sample\n",
    "#         continue\n",
    "    if len(np.unique(ai_mask_list[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "    for name in ai_mask_list[indices]:\n",
    "        gt_file = '{}_gt.png'.format(ai_mask.split('_cutoff')[0])\n",
    "        gt_im = cv2.imread(os.path.join(gt_base, gt_file), cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "        w,h=gt_im.shape\n",
    "\n",
    "        im = cv2.imread(os.path.join(base, name))\n",
    "        im = cv2.resize(im, (h,w),interpolation=cv2.INTER_NEAREST)\n",
    "        imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "        ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if gt_im.sum() == 0: # normal\n",
    "            fppi_cnt += len(ai_contours)\n",
    "\n",
    "        else:\n",
    "            for ai_contour in ai_contours:\n",
    "                _image = np.zeros_like(gt_im)\n",
    "                _image = cv2.drawContours(_image, [ai_contour], 0, color=255, thickness=-1)\n",
    "                if _image[gt_im>0].sum() == 0:\n",
    "                    fppi_cnt += 1\n",
    "\n",
    "        score = fppi_cnt\n",
    "        bootstrapped_scores.append(score)\n",
    "#     print(\"Bootstrap #{} ROC area: {:0.3f}\".format(m + 1, score))\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "print(\"FPPI = {:0.3f} [{:0.3f} - {:0.3}]\".format(fppi, confidence_lower/sum_image, confidence_upper/sum_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated FPPI: 0.4083333333333333\n",
      "FPPI = 0.408 [0.010 - 0.452]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "gt_base = 'D:/lunit/data/img/gt_opt/healthcheck'\n",
    "base = 'D:/lunit/data/img/ai_json(opt)/healthcheck'\n",
    "ai_mask_list = os.listdir(base)\n",
    "sum_image = len(ai_mask_list)\n",
    "\n",
    "fppi_cnt = 0\n",
    "gt_ims= []\n",
    "ai_ims = []\n",
    "for index, ai_mask in enumerate(sorted(ai_mask_list)):\n",
    "    # if index==10:\n",
    "    #     break\n",
    "\n",
    "    gt_file = '{}_gt.png'.format(ai_mask.split('_cutoff')[0])\n",
    "    gt_im = cv2.imread(os.path.join(gt_base, gt_file), cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "#     gt_ims.append(gt_im)\n",
    "    w,h=gt_im.shape\n",
    "#     print(h,w)\n",
    "#     print(\"started reading gt file: {}\".format(gt_file))\n",
    "\n",
    "    im = cv2.imread(os.path.join(base, ai_mask))\n",
    "    im = cv2.resize(im, (h,w),interpolation=cv2.INTER_NEAREST)\n",
    "#     ai_ims.append(im)\n",
    "    imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "    ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     print(gt_im.shape, im.shape)\n",
    "    if gt_im.sum() == 0: # normal\n",
    "        fppi_cnt += len(ai_contours)\n",
    "\n",
    "    else:\n",
    "        for ai_contour in ai_contours:\n",
    "            _image = np.zeros_like(gt_im)\n",
    "            _image = cv2.drawContours(_image, [ai_contour], 0, color=255, thickness=-1)\n",
    "            if _image[gt_im>0].sum() == 0:\n",
    "                fppi_cnt += 1\n",
    "#     print(\"intermediate sum ffpi cnt: {}\".format(fppi_cnt))\n",
    "\n",
    "\n",
    "\n",
    "fppi = fppi_cnt/sum_image\n",
    "print('Calculated FPPI: {}'.format(fppi))\n",
    "\n",
    "# labels = ground truth label list\n",
    "# lables_pred = prediction probability\n",
    "\n",
    "n_bootstraps = 10\n",
    "rng_seed = 42  # control reproducibility\n",
    "bootstrapped_scores = []\n",
    "\n",
    "rng = np.random.RandomState(rng_seed)\n",
    "for m in range(n_bootstraps):\n",
    "    fppi_cnt = 0\n",
    "\n",
    "#     y_true = np.array(gt_ims)\n",
    "#     y_pred = np.array(ai_ims)\n",
    "    ai_mask_list = np.array(ai_mask_list)\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(ai_mask_list), len(ai_mask_list))\n",
    "#     if len(np.unique(y_true[indices])) < 2:\n",
    "#         # We need at least one positive and one negative sample for ROC AUC\n",
    "#         # to be defined: reject the sample\n",
    "#         continue\n",
    "    if len(np.unique(ai_mask_list[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "    for name in ai_mask_list[indices]:\n",
    "        gt_file = '{}_gt.png'.format(ai_mask.split('_cutoff')[0])\n",
    "        gt_im = cv2.imread(os.path.join(gt_base, gt_file), cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "        w,h=gt_im.shape\n",
    "\n",
    "        im = cv2.imread(os.path.join(base, name))\n",
    "        im = cv2.resize(im, (h,w),interpolation=cv2.INTER_NEAREST)\n",
    "        imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "        ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if gt_im.sum() == 0: # normal\n",
    "            fppi_cnt += len(ai_contours)\n",
    "\n",
    "        else:\n",
    "            for ai_contour in ai_contours:\n",
    "                _image = np.zeros_like(gt_im)\n",
    "                _image = cv2.drawContours(_image, [ai_contour], 0, color=255, thickness=-1)\n",
    "                if _image[gt_im>0].sum() == 0:\n",
    "                    fppi_cnt += 1\n",
    "\n",
    "        score = fppi_cnt\n",
    "        bootstrapped_scores.append(score)\n",
    "#     print(\"Bootstrap #{} ROC area: {:0.3f}\".format(m + 1, score))\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "print(\"FPPI = {:0.3f} [{:0.3f} - {:0.3}]\".format(fppi, confidence_lower/sum_image, confidence_upper/sum_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
