{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "import json\n",
    "from func import *\n",
    "import ast\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shutil\n",
    "from scipy.stats import sem\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u2_u14\n",
      "\n",
      "0.907 [0.869 - 0.942]\n",
      "\n",
      "0.905 [0.863 - 0.94]\n",
      "2\n",
      "pvalue=0.2646\n",
      "u3_u15\n",
      "\n",
      "0.896 [0.854 - 0.936]\n",
      "\n",
      "0.909 [0.872 - 0.945]\n",
      "2\n",
      "pvalue=0.0521\n",
      "u4_u16\n",
      "\n",
      "0.853 [0.805 - 0.898]\n",
      "\n",
      "0.86 [0.814 - 0.904]\n",
      "2\n",
      "pvalue=0.5565\n",
      "u5_u17\n",
      "\n",
      "0.833 [0.784 - 0.882]\n",
      "\n",
      "0.879 [0.835 - 0.92]\n",
      "2\n",
      "pvalue=0.0212\n",
      "u6_u18\n",
      "\n",
      "0.861 [0.813 - 0.907]\n",
      "\n",
      "0.886 [0.845 - 0.927]\n",
      "2\n",
      "pvalue=0.9026\n",
      "u7_u19\n",
      "\n",
      "0.829 [0.774 - 0.879]\n",
      "\n",
      "0.875 [0.828 - 0.917]\n",
      "2\n",
      "pvalue=0.0002\n",
      "u8_u20\n",
      "\n",
      "0.89 [0.846 - 0.93]\n",
      "\n",
      "0.914 [0.873 - 0.951]\n",
      "2\n",
      "pvalue=0.0147\n",
      "u9_u21\n",
      "\n",
      "0.847 [0.799 - 0.892]\n",
      "\n",
      "0.857 [0.812 - 0.896]\n",
      "2\n",
      "pvalue=0.9556\n",
      "u10_u22\n",
      "\n",
      "0.859 [0.813 - 0.901]\n",
      "\n",
      "0.866 [0.820 - 0.907]\n",
      "2\n",
      "pvalue=0.8670\n",
      "u11_u23\n",
      "\n",
      "0.87 [0.826 - 0.912]\n",
      "\n",
      "0.879 [0.836 - 0.918]\n",
      "2\n",
      "pvalue=0.8076\n",
      "u12_u24\n",
      "\n",
      "0.817 [0.771 - 0.859]\n",
      "\n",
      "0.872 [0.829 - 0.914]\n",
      "2\n",
      "pvalue=0.0000\n",
      "u13_u25\n",
      "\n",
      "0.854 [0.803 - 0.897]\n",
      "\n",
      "0.884 [0.842 - 0.926]\n",
      "2\n",
      "pvalue=0.7646\n"
     ]
    }
   ],
   "source": [
    "gt_path = './data/review_result_opt/respiratory'\n",
    "opt_path = './data/cxr_opt_respiratory'\n",
    "\n",
    "ais =['without_AI','with_AI']\n",
    "df = pd.DataFrame(columns = ['name','AI' ,'auc_score'])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(2,14):\n",
    "#     if i==13:\n",
    "#         break\n",
    "    user1 = 'u'+str(i)\n",
    "    user2 = 'u'+str(i+12)\n",
    "    print(user1+'_'+user2)\n",
    "    \n",
    "    opt_score = []\n",
    "    for k in range(len(ais)):\n",
    "        df_2 = pd.DataFrame(columns = ['name', 'AI', 'gt' ,'opt', 'opt_prob'])\n",
    "        gt_list = []\n",
    "        opt_list = []\n",
    "        opt_prob_list = []\n",
    "        invisible_cnt = 0\n",
    "        gt_file = glob.glob(gt_path+'/*.json')\n",
    "        opt_file = glob.glob(opt_path+'/'+user1+'_'+user2+'/'+ais[k]+'/*.json')\n",
    "        \n",
    "        for j in range(len(gt_file)):\n",
    "            contours_gt, labels, w, h = json_gt_open(gt_file[j])\n",
    "            contours_opt, contourIds, rating_list, rate = json_opt_open(opt_file[j])\n",
    "#             print(rating_list,rate)\n",
    "            # gt        \n",
    "            if not 'Invisible Nodule' in labels:\n",
    "                if contours_gt:\n",
    "                    gt_label = 1\n",
    "                    gt_list.append(1)\n",
    "                else:\n",
    "                    gt_label = 0\n",
    "                    gt_list.append(0)\n",
    "                \n",
    "                # opt\n",
    "                if contours_opt:\n",
    "                    opt_label = 1\n",
    "                    opt_list.append(1)\n",
    "                    opt_prob = rate/5\n",
    "                    opt_prob_list.append(rate/5)\n",
    "\n",
    "                else:\n",
    "                    opt_label = 0\n",
    "                    opt_list.append(0)\n",
    "                    opt_prob = 0\n",
    "                    opt_prob_list.append(0)\n",
    "                \n",
    "            else:\n",
    "                invisible_cnt+=1\n",
    "            \n",
    "            data_label = {'name':user1+'_'+user2, 'AI':ais[k], 'gt': gt_label, 'opt':opt_label, 'opt_prob':opt_prob}\n",
    "            df_2 = df_2.append(data_label,ignore_index=True)\n",
    "#             df_2.to_csv('./label_csv/'+user1+'_'+user2+'_'+ais[k]+'.csv')           \n",
    "        \n",
    "        opt_score.append(opt_prob_list)    \n",
    "#         print(invisible_cnt)\n",
    "        cm = confusion_matrix(gt_list,opt_list)\n",
    "#         print(cm)\n",
    "        fp,tp,_=roc_curve(gt_list,opt_prob_list)\n",
    "#         print('AUC_'+ais[k]+' : ',auc(fp,tp))\n",
    "        data = {'name':user1+'_'+user2,'AI':ais[k],'auc_score':round(auc(fp,tp),3)}\n",
    "        df = df.append(data,ignore_index=True)\n",
    "        \n",
    "        n_bootstraps = 1000\n",
    "        rng_seed = 42  # control reproducibility\n",
    "        bootstrapped_scores = []\n",
    "\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        for m in range(n_bootstraps):\n",
    "            y_true = np.array(gt_list)\n",
    "            y_pred = np.array(opt_prob_list)\n",
    "            # bootstrap by sampling with replacement on the prediction indices\n",
    "            indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                # We need at least one positive and one negative sample for ROC AUC\n",
    "                # to be defined: reject the sample\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_true[indices], y_pred[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "#             print(\"Bootstrap #{} ROC area: {:0.3f}\".format(m + 1, score))\n",
    "        \n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        # Computing the lower and upper bound of the 90% confidence interval\n",
    "        # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "        # a 95% confidence interval instead.\n",
    "        confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "        confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "        print(round(auc(fp,tp),3), \"[{:0.3f} - {:0.3}]\".format(confidence_lower, confidence_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AI</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u2_u14</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u2_u14</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u3_u15</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u3_u15</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u4_u16</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u4_u16</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u5_u17</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u5_u17</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u6_u18</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u6_u18</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>u7_u19</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u7_u19</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>u8_u20</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>u8_u20</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>u9_u21</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>u9_u21</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>u10_u22</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>u10_u22</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>u11_u23</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>u11_u23</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>u12_u24</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>u12_u24</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>u13_u25</td>\n",
       "      <td>without_AI</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>u13_u25</td>\n",
       "      <td>with_AI</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name          AI  auc_score\n",
       "0    u2_u14  without_AI      0.907\n",
       "1    u2_u14     with_AI      0.905\n",
       "2    u3_u15  without_AI      0.896\n",
       "3    u3_u15     with_AI      0.909\n",
       "4    u4_u16  without_AI      0.853\n",
       "5    u4_u16     with_AI      0.860\n",
       "6    u5_u17  without_AI      0.833\n",
       "7    u5_u17     with_AI      0.879\n",
       "8    u6_u18  without_AI      0.861\n",
       "9    u6_u18     with_AI      0.886\n",
       "10   u7_u19  without_AI      0.829\n",
       "11   u7_u19     with_AI      0.875\n",
       "12   u8_u20  without_AI      0.890\n",
       "13   u8_u20     with_AI      0.914\n",
       "14   u9_u21  without_AI      0.847\n",
       "15   u9_u21     with_AI      0.857\n",
       "16  u10_u22  without_AI      0.859\n",
       "17  u10_u22     with_AI      0.866\n",
       "18  u11_u23  without_AI      0.870\n",
       "19  u11_u23     with_AI      0.879\n",
       "20  u12_u24  without_AI      0.817\n",
       "21  u12_u24     with_AI      0.872\n",
       "22  u13_u25  without_AI      0.854\n",
       "23  u13_u25     with_AI      0.884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_excel('lable.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u2_u11\n",
      "0.682\n",
      "Confidence interval for the score: [0.605 - 0.759]\n",
      "0.695\n",
      "Confidence interval for the score: [0.621 - 0.775]\n",
      "u3_u12\n",
      "0.724\n",
      "Confidence interval for the score: [0.639 - 0.797]\n",
      "0.742\n",
      "Confidence interval for the score: [0.664 - 0.821]\n",
      "u4_u13\n",
      "0.754\n",
      "Confidence interval for the score: [0.667 - 0.836]\n",
      "0.739\n",
      "Confidence interval for the score: [0.647 - 0.823]\n",
      "u5_u14\n",
      "0.717\n",
      "Confidence interval for the score: [0.633 - 0.799]\n",
      "0.726\n",
      "Confidence interval for the score: [0.641 - 0.81]\n",
      "u6_u15\n",
      "0.662\n",
      "Confidence interval for the score: [0.579 - 0.747]\n",
      "0.735\n",
      "Confidence interval for the score: [0.645 - 0.817]\n",
      "u7_u16\n",
      "0.704\n",
      "Confidence interval for the score: [0.626 - 0.781]\n",
      "0.655\n",
      "Confidence interval for the score: [0.579 - 0.728]\n",
      "u8_u17\n",
      "0.733\n",
      "Confidence interval for the score: [0.649 - 0.808]\n",
      "0.726\n",
      "Confidence interval for the score: [0.632 - 0.809]\n",
      "u9_u18\n",
      "0.718\n",
      "Confidence interval for the score: [0.634 - 0.801]\n",
      "0.674\n",
      "Confidence interval for the score: [0.585 - 0.759]\n",
      "u10_u19\n",
      "0.635\n",
      "Confidence interval for the score: [0.554 - 0.713]\n",
      "0.732\n",
      "Confidence interval for the score: [0.645 - 0.819]\n"
     ]
    }
   ],
   "source": [
    "gt_path = './data/review_result_opt/healthcheck'\n",
    "opt_path = './data/cxr_opt_healthcheck'\n",
    "\n",
    "ais =['without_AI','with_AI']\n",
    "df_h = pd.DataFrame(columns = ['name','AI' ,'auc_score'])\n",
    "\n",
    "\n",
    "for i in range(2,11):\n",
    "#     if i==13:\n",
    "#         break\n",
    "    user1 = 'u'+str(i)\n",
    "    user2 = 'u'+str(i+9)\n",
    "\n",
    "    print(user1+'_'+user2)\n",
    "    \n",
    "    opt_score = []\n",
    "    for k in range(len(ais)):\n",
    "\n",
    "        gt_list = []\n",
    "        opt_list = []\n",
    "        opt_prob_list = []\n",
    "        invisible_cnt = 0\n",
    "        gt_file = glob.glob(gt_path+'/*.json')\n",
    "        opt_file = glob.glob(opt_path+'/'+user1+'_'+user2+'/'+ais[k]+'/*.json')\n",
    "        \n",
    "        for j in range(len(gt_file)):\n",
    "            contours_gt, labels, w, h = json_gt_open(gt_file[j])\n",
    "            contours_opt, contourIds, rating_list, rate = json_opt_open(opt_file[j])\n",
    "#             print(rating_list,rate)\n",
    "            # gt        \n",
    "            if not 'Invisible Nodule' in labels:\n",
    "                if contours_gt:\n",
    "                    gt_list.append(1)\n",
    "                else:\n",
    "                    gt_list.append(0)\n",
    "                \n",
    "                # opt\n",
    "                if contours_opt:\n",
    "                    opt_list.append(1)\n",
    "                    opt_prob_list.append(rate/5)\n",
    "\n",
    "                else:\n",
    "                    opt_list.append(0)\n",
    "                    opt_prob_list.append(0)\n",
    "                \n",
    "            else:\n",
    "                invisible_cnt+=1\n",
    "        \n",
    "        opt_score.append(opt_prob_list)\n",
    "#         print(invisible_cnt)\n",
    "        cm = confusion_matrix(gt_list,opt_list)\n",
    "#         print(cm)\n",
    "        fp,tp,_=roc_curve(gt_list,opt_prob_list,pos_label=1)\n",
    "#         print('AUC_'+ais[k]+' : ',auc(fp,tp))\n",
    "        data = {'name':user1+'_'+user2,'AI':ais[k],'auc_score':round(auc(fp,tp),3)}\n",
    "        df_h = df_h.append(data,ignore_index=True)\n",
    "        \n",
    "        print(round(auc(fp,tp),3))\n",
    "        \n",
    "        n_bootstraps = 1000\n",
    "        rng_seed = 42  # control reproducibility\n",
    "        bootstrapped_scores = []\n",
    "\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        for m in range(n_bootstraps):\n",
    "            y_true = np.array(gt_list)\n",
    "            y_pred = np.array(opt_prob_list)\n",
    "            # bootstrap by sampling with replacement on the prediction indices\n",
    "            indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "            if len(np.unique(y_true[indices])) < 2:\n",
    "                # We need at least one positive and one negative sample for ROC AUC\n",
    "                # to be defined: reject the sample\n",
    "                continue\n",
    "\n",
    "            score = roc_auc_score(y_true[indices], y_pred[indices])\n",
    "            bootstrapped_scores.append(score)\n",
    "#             print(\"Bootstrap #{} ROC area: {:0.3f}\".format(m + 1, score))\n",
    "        \n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        # Computing the lower and upper bound of the 90% confidence interval\n",
    "        # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "        # a 95% confidence interval instead.\n",
    "        confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "        confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "        print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(confidence_lower, confidence_upper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
