{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "def ci95(inp):\n",
    "    max95 = np.mean(inp) + (1.96 * (np.std(inp) / math.sqrt(len(inp))))\n",
    "    min95 = np.mean(inp) - (1.96 * (np.std(inp) / math.sqrt(len(inp))))\n",
    "    return min95, max95\n",
    "\n",
    "def dice_coef_score(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "#     print(intersection)\n",
    "    return (2. * intersection) / (np.sum(y_true_f) + np.sum(y_pred_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "cutoff : 0.3\n",
      "--------------------\n",
      "brmh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.51\n",
      "Total count: 2650\n",
      "TP count: 1361\n",
      "FP count: 1289\n",
      "FN count: 619\n",
      "Sensitivity: 0.69\n",
      "====================\n",
      "kyuh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.46\n",
      "Total count: 2061\n",
      "TP count: 1145\n",
      "FP count: 916\n",
      "FN count: 785\n",
      "Sensitivity: 0.59\n",
      "====================\n",
      "gugh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.46\n",
      "Total count: 1648\n",
      "TP count: 969\n",
      "FP count: 679\n",
      "FN count: 403\n",
      "Sensitivity: 0.71\n",
      "====================\n",
      "--------------------\n",
      "cutoff : 0.4\n",
      "--------------------\n",
      "brmh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.56\n",
      "Total count: 2650\n",
      "TP count: 1237\n",
      "FP count: 1413\n",
      "FN count: 752\n",
      "Sensitivity: 0.62\n",
      "====================\n",
      "kyuh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.51\n",
      "Total count: 2061\n",
      "TP count: 1051\n",
      "FP count: 1010\n",
      "FN count: 892\n",
      "Sensitivity: 0.54\n",
      "====================\n",
      "gugh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.51\n",
      "Total count: 1648\n",
      "TP count: 894\n",
      "FP count: 754\n",
      "FN count: 479\n",
      "Sensitivity: 0.65\n",
      "====================\n",
      "--------------------\n",
      "cutoff : 0.5\n",
      "--------------------\n",
      "brmh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.62\n",
      "Total count: 2650\n",
      "TP count: 1086\n",
      "FP count: 1564\n",
      "FN count: 909\n",
      "Sensitivity: 0.54\n",
      "====================\n",
      "kyuh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.55\n",
      "Total count: 2061\n",
      "TP count: 964\n",
      "FP count: 1097\n",
      "FN count: 987\n",
      "Sensitivity: 0.49\n",
      "====================\n",
      "gugh_respiratory\n",
      "====================\n",
      "Calculated FPPI: 0.57\n",
      "Total count: 1648\n",
      "TP count: 807\n",
      "FP count: 841\n",
      "FN count: 570\n",
      "Sensitivity: 0.59\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "name_li = ['brmh','kyuh','gugh']\n",
    "cutoff_values=[0.3,0.4,0.5]\n",
    "\n",
    "for cutoff_value in cutoff_values:\n",
    "    print('-'*20)\n",
    "    print('cutoff : {}'.format(cutoff_value))\n",
    "    print('-'*20)\n",
    "    for name in name_li:\n",
    "        print(name+'_respiratory')\n",
    "        gt_base = 'D:/lunit/01_data_analysis/data/img/result/{}_respiratory/gt_mask'.format(name)\n",
    "        base = 'D:/lunit/01_data_analysis/data/img/ai_json(all_files)/{}_respiratory/ai_mask'.format(name)\n",
    "        ai_mask_list = os.listdir(base)\n",
    "        sum_image = len(ai_mask_list)\n",
    "\n",
    "        fppi_cnt = 0\n",
    "        fn_cnt = 0\n",
    "        tp_cnt = 0\n",
    "\n",
    "        total_cnt=0\n",
    "        gt_ims= []\n",
    "        ai_ims = []\n",
    "        true_detection_rate_li = []\n",
    "        for index, ai_mask in enumerate(sorted(ai_mask_list)):\n",
    "    #         if index==10:\n",
    "    #             break\n",
    "            tp = 0\n",
    "            fn = 0\n",
    "            gt_file = '{}_mask.png'.format(ai_mask.split('_cutoff')[0])\n",
    "            gt_im = cv2.imread(os.path.join(gt_base, gt_file))\n",
    "            w,h,_=gt_im.shape\n",
    "            im = cv2.imread(os.path.join(base, ai_mask))\n",
    "            im = cv2.resize(im, (h,w),interpolation=cv2.INTER_LINEAR)\n",
    "    #         print(gt_file, ai_mask)\n",
    "    #         print(gt_im.shape, im.shape)\n",
    "\n",
    "            imgray = cv2.cvtColor(gt_im,cv2.COLOR_BGR2GRAY)\n",
    "            ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "            gt_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "            ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "            ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #         print(len(gt_contours), len(ai_contours))\n",
    "            total_cnt+=len(ai_contours)\n",
    "        #     print(gt_im.shape, im.shape)\n",
    "            if gt_im.sum() == 0: # normal\n",
    "                fppi_cnt += len(ai_contours)\n",
    "\n",
    "            elif im.sum()==0:\n",
    "                fn_cnt += len(gt_contours)\n",
    "                fn+=1\n",
    "\n",
    "            else:\n",
    "                for ai_contour in ai_contours:\n",
    "                    _image = np.zeros_like(gt_im)\n",
    "                    _image_ai = cv2.drawContours(_image, [ai_contour], 0, color=1, thickness=-1)\n",
    "    #                 if _image[gt_im>0].sum() == 0:\n",
    "    #                 dsc = dice_coef_score(gt_im/255, _image)\n",
    "    #                 if dsc<cutoff_value:\n",
    "    #                     print(dsc)\n",
    "    #                     fppi_cnt += 1\n",
    "                    dsc_li=[]\n",
    "                    for gt_contour in gt_contours:\n",
    "                        _image = np.zeros_like(gt_im)\n",
    "                        _image_gt = cv2.drawContours(_image, [gt_contour], 0, color=1, thickness=-1)\n",
    "\n",
    "        #                 if _image[im>0].sum() == 0:\n",
    "    #                     print(dice_coef_score(_image_gt, _image_ai))\n",
    "                        dsc_li.append(dice_coef_score(_image_gt, _image_ai))\n",
    "\n",
    "                    if max(dsc_li) < cutoff_value:\n",
    "                        fppi_cnt += 1\n",
    "                    else:\n",
    "                        tp_cnt+=1\n",
    "\n",
    "                for gt_contour in gt_contours:\n",
    "                    _image = np.zeros_like(gt_im)\n",
    "                    _image_gt = cv2.drawContours(_image, [gt_contour], 0, color=1, thickness=-1)\n",
    "\n",
    "    #                 if _image[gt_im>0].sum() == 0:\n",
    "    #                 dsc = dice_coef_score(gt_im/255, _image)\n",
    "    #                 if dsc<cutoff_value:\n",
    "    #                     print(dsc)\n",
    "    #                     fppi_cnt += 1\n",
    "                    dsc_li=[]\n",
    "                    for ai_contour in ai_contours:\n",
    "                        _image = np.zeros_like(gt_im)\n",
    "                        _image_ai = cv2.drawContours(_image, [ai_contour], 0, color=1, thickness=-1)\n",
    "        #                 if _image[im>0].sum() == 0:\n",
    "    #                     print(dice_coef_score(_image_gt, _image_ai))\n",
    "                        dsc_li.append(dice_coef_score(_image_ai, _image_gt))\n",
    "\n",
    "                    if max(dsc_li) < cutoff_value:\n",
    "                        fn_cnt += 1\n",
    "\n",
    "    #         if tp+fn>0:\n",
    "    #             true_detection_rate = tp/(tp+fn)\n",
    "    #             true_detection_rate_li.append(true_detection_rate)\n",
    "    #         else:\n",
    "    #             true_detection_rate_li.append(1)\n",
    "\n",
    "    #         print(total_cnt, tp_cnt, fn_cnt)        \n",
    "        #     print(\"intermediate sum ffpi cnt: {}\".format(fppi_cnt))\n",
    "\n",
    "\n",
    "\n",
    "        fppi = fppi_cnt/sum_image\n",
    "        print('='*20)\n",
    "        print('Calculated FPPI: {:0.2f}'.format(fppi))\n",
    "        print('Total count: {}'.format(total_cnt))\n",
    "        print('TP count: {}'.format(tp_cnt))\n",
    "        print('FP count: {}'.format(fppi_cnt))\n",
    "        print('FN count: {}'.format(fn_cnt))\n",
    "        print('Sensitivity: {:0.2f}'.format(tp_cnt/(tp_cnt+fn_cnt)))\n",
    "        print('='*20)\n",
    "    #     true_detection_rate = tp_cnt/(tp_cnt+fn_cnt)\n",
    "    #     min_ci, max_ci = ci95(np.array(true_detection_rate_li))\n",
    "    #     print('true_detection_rate: {:0.2f} ({:0.2f}, {:0.2f})'.format(true_detection_rate, min_ci, max_ci))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPPI 계산 (CI 구간 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brmh_healthcheck\n",
      "Calculated FPPI: 0.3547815820543093\n",
      "kyuh_healthcheck\n",
      "Calculated FPPI: 0.17987152034261242\n",
      "gugh_healthcheck\n",
      "Calculated FPPI: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "names = ['brmh_healthcheck','kyuh_healthcheck','gugh_healthcheck']\n",
    "for name in names:\n",
    "    gt_base = 'D:/lunit/data/img/result/'+name+'/gt_mask'\n",
    "    base = 'D:/lunit/data/img/ai_json(all_files)/'+name+'/ai_mask'\n",
    "    ai_mask_list = os.listdir(base)\n",
    "    sum_image = len(ai_mask_list)\n",
    "\n",
    "    fppi_cnt = 0\n",
    "    for index, ai_mask in enumerate(sorted(ai_mask_list)):\n",
    "        # if index==10:\n",
    "        #     break\n",
    "\n",
    "        gt_file = '{}_mask.png'.format(ai_mask.split('_cutoff')[0])\n",
    "        gt_im = cv2.imread(os.path.join(gt_base, gt_file), cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "        w,h=gt_im.shape\n",
    "    #     print(h,w)\n",
    "    #     print(\"started reading gt file: {}\".format(gt_file))\n",
    "\n",
    "        im = cv2.imread(os.path.join(base, ai_mask))\n",
    "        im = cv2.resize(im, (h,w))\n",
    "        imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "        ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if gt_im.sum() == 0: # normal\n",
    "            fppi_cnt += len(ai_contours)\n",
    "\n",
    "        else:\n",
    "            for ai_contour in ai_contours:\n",
    "                _image = np.zeros_like(gt_im)\n",
    "                _image = cv2.drawContours(_image, [ai_contour], 0, color=255, thickness=-1)\n",
    "                if _image[gt_im>0].sum() == 0:\n",
    "                    fppi_cnt += 1\n",
    "    #     print(\"intermediate sum ffpi cnt: {}\".format(fppi_cnt))\n",
    "\n",
    "    print(name)\n",
    "    print('Calculated FPPI: {}'.format(fppi_cnt/sum_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
