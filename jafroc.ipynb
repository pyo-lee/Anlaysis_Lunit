{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import metric\n",
    "import pprint\n",
    "import argparse\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "\n",
    "UINT8_MAX = np.iinfo(np.uint8).max\n",
    "UINT16_MAX = np.iinfo(np.uint16).max\n",
    "\n",
    "#from visual import make_overlay_image, make_overlay_image2\n",
    "#import visual as visual_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_array(contour):\n",
    "    arr = [[row[\"x\"], row[\"y\"]] for row in contour]\n",
    "    arr = np.array(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(contours, width, height, dtype=np.float32, mask_size=1000):\n",
    "    assert isinstance(contours, list) or isinstance(contours, tuple)\n",
    "\n",
    "    images = []\n",
    "    for contour in contours:\n",
    "        for conts in contour:\n",
    "            images.append(get_mask(conts, width, height, dtype, mask_size=mask_size))\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(contour, width, height, dtype=np.float32, mask_size=1000):\n",
    "    if width < height:\n",
    "        mask_height = mask_size\n",
    "        mask_width = int(mask_size * width / height)\n",
    "    else:\n",
    "        mask_width = mask_size\n",
    "        mask_height = int(mask_size * height / width)\n",
    "\n",
    "    image = np.zeros((mask_height, mask_width), np.uint8)\n",
    "\n",
    "    assert len(contour) > 0\n",
    "\n",
    "    for subcontour in contour:\n",
    "        assert len(subcontour) > 0\n",
    "        pts = np.array(\n",
    "            [[[(x + width / 2) / width * mask_width, (y + height / 2) / height * mask_height]] for x, y in subcontour],\n",
    "            np.int32)\n",
    "        cv2.fillPoly(image, [pts], (255, 255, 255))\n",
    "    return convert_image_type(image, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_type(image, dtype=np.float32):\n",
    "    if image.dtype == np.uint8:\n",
    "\n",
    "        if dtype == np.float32:\n",
    "            image = image.astype(np.float32)\n",
    "            image /= UINT8_MAX\n",
    "            return image\n",
    "        elif dtype == np.uint8:\n",
    "            return image\n",
    "        else:\n",
    "            raise TypeError('numpy.float32 or numpy.uint8 supported as a target dtype')\n",
    "\n",
    "    elif image.dtype == np.uint16:\n",
    "\n",
    "        if dtype == np.float32:\n",
    "            image = image.astype(np.float32)\n",
    "            image /= UINT16_MAX\n",
    "            return image\n",
    "        elif dtype == np.uint8:\n",
    "            image = image.astype(np.float32)\n",
    "            image *= UINT8_MAX / UINT16_MAX\n",
    "            image = image.astype(np.uint8)\n",
    "            return image\n",
    "        elif dtype == np.uint16:\n",
    "            return image\n",
    "        else:\n",
    "            raise TypeError('numpy.float32 or numpy.uint8 or numpy.uint16 supported as a target dtype')\n",
    "\n",
    "    else:\n",
    "        raise TypeError('numpy.uint8 or numpy.uint16 supported as an input dtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_output(pixel_array, human_data):\n",
    "    _dict = eval(human_data['contour_list'])\n",
    "    _ratings = eval(human_data['rating_list'])\n",
    "\n",
    "    height, width = pixel_array.shape\n",
    "\n",
    "    if _ratings:\n",
    "        masks = []\n",
    "        for _key in _dict.keys():\n",
    "            _contour = _dict[_key]\n",
    "\n",
    "            for _rating in _ratings:\n",
    "                if _rating['contourId']  == _key:\n",
    "                    lesion_rating = _rating['rating']\n",
    "\n",
    "            arr = convert_dict_to_array(_contour)\n",
    "\n",
    "            arr[..., :, 0] = arr[:, 0] * width - width / 2\n",
    "            arr[..., :, 1] = arr[:, 1] * height - height / 2\n",
    "\n",
    "            arr = arr.astype(np.int64)\n",
    "\n",
    "            arr = np.expand_dims(arr, 0)\n",
    "            arr = np.expand_dims(arr, 0)\n",
    "\n",
    "            mask = sum(get_masks([arr], width=width, height=height, mask_size=max(width, height)))\n",
    "            mask = mask * (float(lesion_rating)/5)\n",
    "            masks.append(mask)\n",
    "\n",
    "        final_mask = np.stack(masks, axis=0).max(0)\n",
    "\n",
    "    else:\n",
    "        final_mask = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_final_mask(data):\n",
    "    if 'abnormal_finding' in data.keys() and data['abnormal_finding']:\n",
    "        masks = []\n",
    "        for _dict in data['abnormal_finding']:\n",
    "#             if _dict['label_text'] in mca_list:\n",
    "            if _dict['label_text']:\n",
    "                for contour_key in _dict['contour_list'].keys():\n",
    "                    contour = _dict['contour_list'][contour_key]\n",
    "                    arr = convert_dict_to_array(contour)\n",
    "                    # print(width, height)\n",
    "                    # print(arr)\n",
    "\n",
    "                    # print(width, height)\n",
    "                    # print(arr)\n",
    "\n",
    "                    arr[..., :, 0] = arr[:, 0]\n",
    "                    arr[..., :, 1] = arr[:, 1]\n",
    "                    arr = arr.astype(np.int64)\n",
    "\n",
    "                    arr = np.expand_dims(arr, 0)\n",
    "                    arr = np.expand_dims(arr, 0)\n",
    "\n",
    "                    mask = sum(get_masks([arr], width=width, height=height, mask_size=max(width, height)))\n",
    "                    masks.append(mask)\n",
    "            else:\n",
    "                mask = np.zeros((height, width), dtype=np.float32)\n",
    "                masks.append(mask)\n",
    "\n",
    "        final_mask = np.stack(masks, axis=0).max(0)\n",
    "    else:\n",
    "        final_mask = np.zeros((height, width), dtype=np.float32)\n",
    "        \n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u2_u14']\n",
      "u2_u14\n",
      "92 138\n",
      "[0.6, 0.0, 0.0, 0.8, 0.0, 0.8, 0.4, 0.6, 0.8, 0.8, 0.4, 0.0, 0.8, 0.6, 0.6, 0.4, 0.0, 0.0, 0.8, 0.0, 0.2, 0.0, 0.6, 0.8, 0.0, 0.6, 0.0, 0.0, 0.0, 0.4, 0.6, 0.0, 0.6, 0.6, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.4, 0.8, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.6, 0.2, 0.6, 0.0, 0.4, 0.6, 0.0, 0.4, 0.0, 0.0, 0.8, 0.6, 0.6, 0.4, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.2, 0.2, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0] [[0.8, 0.8], [1.0, 1.0, 1.0], [0.8, 0.8], [1.0, 1.0], [0.6], [0.0], [0.8, 0.8], [1.0, 1.0, 1.0, 1.0], [1.0, 1.0], [1.0], [1.0, 1.0], [0.8], [1.0], [1.0], [0.6], [0.8], [0.8, 0.8], [0.8], [1.0], [1.0, 1.0], [1.0, 1.0], [1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [0.8, 0.8], [0.8], [0.6], [1.0], [1.0, 1.0], [1.0], [0.8, 0.8], [1.0, 1.0, 1.0, 1.0], [0.6], [1.0], [0.8], [1.0], [0.8, 0.8], [1.0], [0.4], [0.8, 0.8], [0.6], [1.0, 1.0], [1.0], [0.8], [1.0], [1.0, 1.0], [0.0], [0.8], [1.0, 1.0], [1.0, 1.0, 1.0], [0.8], [0.0], [0.6, 0.6], [0.6, 0.6], [0.4], [1.0], [1.0], [0.4], [1.0], [0.6, 0.6, 0.6, 0.6], [1.0, 1.0, 1.0], [1.0, 1.0], [0.8], [1.0, 1.0], [1.0, 1.0, 1.0], [0.6, 0.6], [0.8], [1.0, 1.0], [0.8, 0.8], [0.8], [0.6], [1.0, 1.0], [0.2, 0.2], [0.4], [0.6, 0.6], [0.0], [1.0], [1.0], [0.8, 0.8, 0.8], [1.0, 1.0], [0.8], [1.0], [0.8], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0], [1.0, 1.0], [0.8, 0.8], [1.0], [0.8], [0.8], [0.8, 0.8], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0], [1.0, 1.0], [0.8], [0.8], [1.0], [1.0, 1.0], [0.8, 0.8], [0.8, 0.8], [1.0], [1.0, 1.0, 1.0, 1.0], [1.0], [0.6], [1.0], [0.0], [0.4], [0.8], [1.0], [0.6, 0.6], [0.6, 0.6, 0.6], [0.6, 0.6], [0.6], [0.6, 0.6], [1.0], [1.0, 1.0], [1.0, 1.0], [0.8, 0.8, 0.8], [0.6], [0.8, 0.8], [1.0], [0.6, 0.6], [0.6, 0.6, 0.6, 0.6], [0.4], [0.6, 0.6], [1.0], [1.0, 1.0], [0.6, 0.6], [0.6], [1.0, 1.0], [0.0], [1.0]]\n",
      "jafroc:\t0.907\n"
     ]
    }
   ],
   "source": [
    "mapping_df = pd.read_csv('./data/brmh_1_mapping_table_respiratory.csv')\n",
    "mapping_cases = mapping_df['case_no'].tolist()\n",
    "\n",
    "interest_list = []\n",
    "for i in range(2):\n",
    "    interest_list.append('u{}_u{}'.format(str(i+2),str(i+14)))\n",
    "\n",
    "#interest_list = ['u2/t2']\n",
    "print(interest_list)\n",
    "\n",
    "with open('jafroc_respiratory(opt_resp).txt', 'w') as csvfile:\n",
    "    for interest_dir in interest_list:\n",
    "#         print(interest_dir)\n",
    "        gt_masks = []\n",
    "        human_masks = []\n",
    "        for index, file_name in enumerate(mapping_cases):\n",
    "            if file_name.split('-')[0] == 'B':\n",
    "                hospital_name = 'brmh'\n",
    "            elif file_name.split('-')[0] == 'K':\n",
    "                hospital_name = 'kyuh'\n",
    "            elif file_name.split('-')[0] == 'G':\n",
    "                hospital_name = 'gugh'\n",
    "            else:\n",
    "                raise ValueError('invalid hospital name')\n",
    "\n",
    "            json_root_path = 'D:/lunit/data/review_result_20200705/{}-A1/{}/respiratory'.format(hospital_name.upper(), hospital_name)\n",
    "            json_file = os.path.join(json_root_path, (file_name+'.dcm.json'))\n",
    "\n",
    "#             heatmap_root_path = '/storage2/ctr/original/cxr/external_validation/BRMH-GIL-KONYANG/{}/respiratory'.format(hospital_name)\n",
    "\n",
    "            with open(json_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "#             handler = dicom_handler.get_handler(os.path.join(heatmap_root_path, (file_name+'.dcm')), modality='CXR')\n",
    "#             pixel_array = handler.pixels\n",
    "#             pixel_array = (pixel_array * 255).astype(np.uint8)\n",
    "            height, width = data['height'], data['width']\n",
    "            pixel_array = np.zeros((height,width))\n",
    "\n",
    "#             mca_list = ['Nodule / Mass', 'Consolidation', 'Pneumothorax']\n",
    "#             mca_list = ['Nodule / Mass']\n",
    "            mca_list = ['Consolidation']\n",
    "#             mca_list = ['Pneumothorax']\n",
    "            gt_masks.append(get_gt_final_mask(data))\n",
    "\n",
    "            human_root_path = 'D:/lunit/data/cxr_opt_respiratory'\n",
    "            human_json_name = str(mapping_df['seq'].tolist()[index]) + '.json'\n",
    "            human_json_full = os.path.join(human_root_path, interest_dir, 'without_AI', human_json_name)\n",
    "            with open(human_json_full, \"r\") as f:\n",
    "                human_data = json.load(f)\n",
    "\n",
    "            human_masks.append(get_human_output(pixel_array, human_data))\n",
    "\n",
    "        new_shape = (512, 512)\n",
    "        human_outputs = [cv2.resize(np.asarray(human_mask), new_shape, interpolation=cv2.INTER_NEAREST) for human_mask in human_masks]\n",
    "\n",
    "        gt_masks = [gt_mask.astype(bool) for gt_mask in gt_masks]\n",
    "\n",
    "\n",
    "        resized_human_outputs = []\n",
    "        for index, human_output in enumerate(human_outputs):\n",
    "            resized_human_outputs.append(np.resize(human_output, gt_masks[index].shape))\n",
    "\n",
    "        jafroc_value = metric.jafroc(resized_human_outputs, gt_masks)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value), file=csvfile)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value))\n",
    "\n",
    "        jaf_ci = metric.bootstrap_jafroc_ci(resized_human_outputs, gt_masks, n_bootstraps=100, alpha=0.05, rng_seed=123)\n",
    "        print(jaf_ci, file=csvfile)\n",
    "        print(jaf_ci)\n",
    "              \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u2_u14', 'u3_u15', 'u4_u16', 'u5_u17', 'u6_u18', 'u7_u19', 'u8_u20', 'u9_u21', 'u10_u22', 'u11_u23', 'u12_u24', 'u13_u25']\n",
      "u2_u14\n",
      "jafroc:\t0.905\n",
      "(0.873, 0.937)\n",
      "u3_u15\n",
      "jafroc:\t0.909\n",
      "(0.874, 0.949)\n",
      "u4_u16\n",
      "jafroc:\t0.856\n",
      "(0.818, 0.91)\n",
      "u5_u17\n",
      "jafroc:\t0.878\n",
      "(0.831, 0.922)\n",
      "u6_u18\n",
      "jafroc:\t0.886\n",
      "(0.845, 0.921)\n",
      "u7_u19\n",
      "jafroc:\t0.875\n",
      "(0.828, 0.921)\n",
      "u8_u20\n",
      "jafroc:\t0.914\n",
      "(0.875, 0.951)\n",
      "u9_u21\n",
      "jafroc:\t0.857\n",
      "(0.822, 0.894)\n",
      "u10_u22\n",
      "jafroc:\t0.866\n",
      "(0.833, 0.905)\n",
      "u11_u23\n",
      "jafroc:\t0.879\n",
      "(0.836, 0.922)\n",
      "u12_u24\n",
      "jafroc:\t0.872\n",
      "(0.825, 0.919)\n",
      "u13_u25\n",
      "jafroc:\t0.884\n",
      "(0.849, 0.924)\n"
     ]
    }
   ],
   "source": [
    "mapping_df = pd.read_csv('./data/brmh_1_mapping_table_respiratory.csv')\n",
    "mapping_cases = mapping_df['case_no'].tolist()\n",
    "\n",
    "interest_list = []\n",
    "for i in range(12):\n",
    "    interest_list.append('u{}_u{}'.format(str(i+2),str(i+14)))\n",
    "\n",
    "#interest_list = ['u2/t2']\n",
    "print(interest_list)\n",
    "\n",
    "with open('jafroc_respiratory(opt_resp).txt', 'w') as csvfile:\n",
    "    for interest_dir in interest_list:\n",
    "        print(interest_dir)\n",
    "        gt_masks = []\n",
    "        human_masks = []\n",
    "        for index, file_name in enumerate(mapping_cases):\n",
    "            if file_name.split('-')[0] == 'B':\n",
    "                hospital_name = 'brmh'\n",
    "            elif file_name.split('-')[0] == 'K':\n",
    "                hospital_name = 'kyuh'\n",
    "            elif file_name.split('-')[0] == 'G':\n",
    "                hospital_name = 'gugh'\n",
    "            else:\n",
    "                raise ValueError('invalid hospital name')\n",
    "\n",
    "            json_root_path = 'D:/lunit/data/review_result_20200705/{}-A1/{}/respiratory'.format(hospital_name.upper(), hospital_name)\n",
    "            json_file = os.path.join(json_root_path, (file_name+'.dcm.json'))\n",
    "\n",
    "#             heatmap_root_path = '/storage2/ctr/original/cxr/external_validation/BRMH-GIL-KONYANG/{}/respiratory'.format(hospital_name)\n",
    "\n",
    "            with open(json_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "#             handler = dicom_handler.get_handler(os.path.join(heatmap_root_path, (file_name+'.dcm')), modality='CXR')\n",
    "#             pixel_array = handler.pixels\n",
    "#             pixel_array = (pixel_array * 255).astype(np.uint8)\n",
    "            height, width = data['height'], data['width']\n",
    "            pixel_array = np.zeros((height,width))\n",
    "\n",
    "#             mca_list = ['Nodule / Mass', 'Consolidation', 'Pneumothorax']\n",
    "#             mca_list = ['Nodule / Mass']\n",
    "            mca_list = ['Consolidation']\n",
    "#             mca_list = ['Pneumothorax']\n",
    "            gt_masks.append(get_gt_final_mask(data))\n",
    "\n",
    "            human_root_path = 'D:/lunit/data/cxr_opt_respiratory'\n",
    "            human_json_name = str(mapping_df['seq'].tolist()[index]) + '.json'\n",
    "            human_json_full = os.path.join(human_root_path, interest_dir, 'with_AI', human_json_name)\n",
    "            with open(human_json_full, \"r\") as f:\n",
    "                human_data = json.load(f)\n",
    "\n",
    "            human_masks.append(get_human_output(pixel_array, human_data))\n",
    "\n",
    "        new_shape = (512, 512)\n",
    "        human_outputs = [cv2.resize(np.asarray(human_mask), new_shape, interpolation=cv2.INTER_NEAREST) for human_mask in human_masks]\n",
    "\n",
    "        gt_masks = [gt_mask.astype(bool) for gt_mask in gt_masks]\n",
    "\n",
    "\n",
    "        resized_human_outputs = []\n",
    "        for index, human_output in enumerate(human_outputs):\n",
    "            resized_human_outputs.append(np.resize(human_output, gt_masks[index].shape))\n",
    "\n",
    "        jafroc_value = metric.jafroc(resized_human_outputs, gt_masks)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value), file=csvfile)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value))\n",
    "\n",
    "        jaf_ci = metric.bootstrap_jafroc_ci(resized_human_outputs, gt_masks, n_bootstraps=100, alpha=0.05, rng_seed=123)\n",
    "        print(jaf_ci, file=csvfile)\n",
    "        print(jaf_ci)\n",
    "              \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u2_u11', 'u3_u12', 'u4_u13', 'u5_u14', 'u6_u15', 'u7_u16', 'u8_u17', 'u9_u18', 'u10_u19']\n",
      "u2_u11\n",
      "jafroc:\t0.646\n",
      "(0.603, 0.737)\n",
      "u3_u12\n",
      "jafroc:\t0.718\n",
      "(0.642, 0.793)\n",
      "u4_u13\n",
      "jafroc:\t0.701\n",
      "(0.628, 0.8)\n",
      "u5_u14\n",
      "jafroc:\t0.704\n",
      "(0.641, 0.778)\n",
      "u6_u15\n",
      "jafroc:\t0.664\n",
      "(0.59, 0.735)\n",
      "u7_u16\n",
      "jafroc:\t0.696\n",
      "(0.627, 0.758)\n",
      "u8_u17\n",
      "jafroc:\t0.718\n",
      "(0.635, 0.797)\n",
      "u9_u18\n",
      "jafroc:\t0.689\n",
      "(0.601, 0.752)\n",
      "u10_u19\n",
      "jafroc:\t0.635\n",
      "(0.575, 0.694)\n"
     ]
    }
   ],
   "source": [
    "mapping_df = pd.read_csv('./data/brmh_2_mapping_table_healthcheck.csv')\n",
    "mapping_cases = mapping_df['case_no'].tolist()\n",
    "\n",
    "interest_list = []\n",
    "for i in range(9):\n",
    "    interest_list.append('u{}_u{}'.format(str(i+2),str(i+11)))\n",
    "\n",
    "#interest_list = ['u2/t2']\n",
    "print(interest_list)\n",
    "\n",
    "with open('jafroc_respiratory(opt_health).txt', 'w') as csvfile:\n",
    "    for interest_dir in interest_list:\n",
    "        print(interest_dir)\n",
    "        gt_masks = []\n",
    "        human_masks = []\n",
    "        for index, file_name in enumerate(mapping_cases):\n",
    "            if file_name.split('-')[0] == 'B':\n",
    "                hospital_name = 'brmh'\n",
    "            elif file_name.split('-')[0] == 'K':\n",
    "                hospital_name = 'kyuh'\n",
    "            elif file_name.split('-')[0] == 'G':\n",
    "                hospital_name = 'gugh'\n",
    "            else:\n",
    "                raise ValueError('invalid hospital name')\n",
    "\n",
    "            json_root_path = 'D:/lunit/data/review_result_20200705/{}-A2/{}/healthcheck'.format(hospital_name.upper(), hospital_name)\n",
    "            json_file = os.path.join(json_root_path, (file_name+'.dcm.json'))\n",
    "\n",
    "#             heatmap_root_path = '/storage2/ctr/original/cxr/external_validation/BRMH-GIL-KONYANG/{}/respiratory'.format(hospital_name)\n",
    "\n",
    "            with open(json_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "#             handler = dicom_handler.get_handler(os.path.join(heatmap_root_path, (file_name+'.dcm')), modality='CXR')\n",
    "#             pixel_array = handler.pixels\n",
    "#             pixel_array = (pixel_array * 255).astype(np.uint8)\n",
    "            height, width = data['height'], data['width']\n",
    "            pixel_array = np.zeros((height,width))\n",
    "\n",
    "#             mca_list = ['Nodule / Mass', 'Consolidation', 'Pneumothorax']\n",
    "#             mca_list = ['Nodule / Mass']\n",
    "            mca_list = ['Consolidation']\n",
    "#             mca_list = ['Pneumothorax']\n",
    "            gt_masks.append(get_gt_final_mask(data))\n",
    "\n",
    "            human_root_path = 'D:/lunit/data/cxr_opt_healthcheck'\n",
    "            human_json_name = str(mapping_df['seq'].tolist()[index]) + '.json'\n",
    "            human_json_full = os.path.join(human_root_path, interest_dir, 'without_AI', human_json_name)\n",
    "            with open(human_json_full, \"r\") as f:\n",
    "                human_data = json.load(f)\n",
    "\n",
    "            human_masks.append(get_human_output(pixel_array, human_data))\n",
    "\n",
    "        new_shape = (512, 512)\n",
    "        human_outputs = [cv2.resize(np.asarray(human_mask), new_shape, interpolation=cv2.INTER_NEAREST) for human_mask in human_masks]\n",
    "\n",
    "        gt_masks = [gt_mask.astype(bool) for gt_mask in gt_masks]\n",
    "\n",
    "\n",
    "        resized_human_outputs = []\n",
    "        for index, human_output in enumerate(human_outputs):\n",
    "            resized_human_outputs.append(np.resize(human_output, gt_masks[index].shape))\n",
    "\n",
    "        jafroc_value = metric.jafroc(resized_human_outputs, gt_masks)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value), file=csvfile)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value))\n",
    "\n",
    "        jaf_ci = metric.bootstrap_jafroc_ci(resized_human_outputs, gt_masks, n_bootstraps=100, alpha=0.05, rng_seed=123)\n",
    "        print(jaf_ci, file=csvfile)\n",
    "        print(jaf_ci)\n",
    "              \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u2_u11', 'u3_u12', 'u4_u13', 'u5_u14', 'u6_u15', 'u7_u16', 'u8_u17', 'u9_u18', 'u10_u19']\n",
      "u2_u11\n",
      "jafroc:\t0.659\n",
      "(0.595, 0.718)\n",
      "u3_u12\n",
      "jafroc:\t0.700\n",
      "(0.602, 0.766)\n",
      "u4_u13\n",
      "jafroc:\t0.679\n",
      "(0.587, 0.762)\n",
      "u5_u14\n",
      "jafroc:\t0.684\n",
      "(0.609, 0.756)\n",
      "u6_u15\n",
      "jafroc:\t0.698\n",
      "(0.614, 0.774)\n",
      "u7_u16\n",
      "jafroc:\t0.632\n",
      "(0.571, 0.689)\n",
      "u8_u17\n",
      "jafroc:\t0.702\n",
      "(0.626, 0.754)\n",
      "u9_u18\n",
      "jafroc:\t0.653\n",
      "(0.565, 0.734)\n",
      "u10_u19\n",
      "jafroc:\t0.691\n",
      "(0.593, 0.772)\n"
     ]
    }
   ],
   "source": [
    "mapping_df = pd.read_csv('./data/brmh_2_mapping_table_healthcheck.csv')\n",
    "mapping_cases = mapping_df['case_no'].tolist()\n",
    "\n",
    "interest_list = []\n",
    "for i in range(9):\n",
    "    interest_list.append('u{}_u{}'.format(str(i+2),str(i+11)))\n",
    "\n",
    "#interest_list = ['u2/t2']\n",
    "print(interest_list)\n",
    "\n",
    "with open('jafroc_respiratory(opt_health).txt', 'w') as csvfile:\n",
    "    for interest_dir in interest_list:\n",
    "        print(interest_dir)\n",
    "        gt_masks = []\n",
    "        human_masks = []\n",
    "        for index, file_name in enumerate(mapping_cases):\n",
    "            if file_name.split('-')[0] == 'B':\n",
    "                hospital_name = 'brmh'\n",
    "            elif file_name.split('-')[0] == 'K':\n",
    "                hospital_name = 'kyuh'\n",
    "            elif file_name.split('-')[0] == 'G':\n",
    "                hospital_name = 'gugh'\n",
    "            else:\n",
    "                raise ValueError('invalid hospital name')\n",
    "\n",
    "            json_root_path = 'D:/lunit/data/review_result_20200705/{}-A2/{}/healthcheck'.format(hospital_name.upper(), hospital_name)\n",
    "            json_file = os.path.join(json_root_path, (file_name+'.dcm.json'))\n",
    "\n",
    "#             heatmap_root_path = '/storage2/ctr/original/cxr/external_validation/BRMH-GIL-KONYANG/{}/respiratory'.format(hospital_name)\n",
    "\n",
    "            with open(json_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "#             handler = dicom_handler.get_handler(os.path.join(heatmap_root_path, (file_name+'.dcm')), modality='CXR')\n",
    "#             pixel_array = handler.pixels\n",
    "#             pixel_array = (pixel_array * 255).astype(np.uint8)\n",
    "            height, width = data['height'], data['width']\n",
    "            pixel_array = np.zeros((height,width))\n",
    "\n",
    "#             mca_list = ['Nodule / Mass', 'Consolidation', 'Pneumothorax']\n",
    "#             mca_list = ['Nodule / Mass']\n",
    "#             mca_list = ['Consolidation']\n",
    "#             mca_list = ['Pneumothorax']\n",
    "            gt_masks.append(get_gt_final_mask(data))\n",
    "\n",
    "            human_root_path = 'D:/lunit/data/cxr_opt_healthcheck'\n",
    "            human_json_name = str(mapping_df['seq'].tolist()[index]) + '.json'\n",
    "            human_json_full = os.path.join(human_root_path, interest_dir, 'with_AI', human_json_name)\n",
    "            with open(human_json_full, \"r\") as f:\n",
    "                human_data = json.load(f)\n",
    "\n",
    "            human_masks.append(get_human_output(pixel_array, human_data))\n",
    "\n",
    "        new_shape = (512, 512)\n",
    "        human_outputs = [cv2.resize(np.asarray(human_mask), new_shape, interpolation=cv2.INTER_NEAREST) for human_mask in human_masks]\n",
    "\n",
    "        gt_masks = [gt_mask.astype(bool) for gt_mask in gt_masks]\n",
    "\n",
    "\n",
    "        resized_human_outputs = []\n",
    "        for index, human_output in enumerate(human_outputs):\n",
    "            resized_human_outputs.append(np.resize(human_output, gt_masks[index].shape))\n",
    "\n",
    "        jafroc_value = metric.jafroc(resized_human_outputs, gt_masks)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value), file=csvfile)\n",
    "        print(\"jafroc:\\t{:.3f}\".format(jafroc_value))\n",
    "\n",
    "        jaf_ci = metric.bootstrap_jafroc_ci(resized_human_outputs, gt_masks, n_bootstraps=100, alpha=0.05, rng_seed=123)\n",
    "        print(jaf_ci, file=csvfile)\n",
    "        print(jaf_ci)\n",
    "              \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
