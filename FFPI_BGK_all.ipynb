{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated FPPI: 0.3837920489296636\n",
      "gugh\n",
      "FPPI = 0.3838 [0.010 - 0.376]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "name_li = ['brmh','kyuh','gugh']\n",
    "fppi_cnt = 0\n",
    "sum_images = 0\n",
    "ai_li=[]\n",
    "for name in name_li:\n",
    "    gt_base = './data/img/result/{}_healthcheck/gt_mask'.format(name)\n",
    "    base = './data/img/ai_json(all_files)/{}_healthcheck/ai_mask'.format(name)\n",
    "    ai_mask_list = os.listdir(base)\n",
    "    sum_image = len(ai_mask_list)\n",
    "    sum_images+=sum_image\n",
    "\n",
    "    \n",
    "    for index, ai_mask in enumerate(sorted(ai_mask_list)):\n",
    "        # if index==10:\n",
    "        #     break\n",
    "        ai_li.append(ai_mask)\n",
    "        gt_file = '{}_mask.png'.format(ai_mask.split('_cutoff')[0])\n",
    "        gt_im = cv2.imread(os.path.join(gt_base, gt_file), cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "        gt_ims.append(gt_im)\n",
    "        w,h=gt_im.shape\n",
    "    #     print(h,w)\n",
    "    #     print(\"started reading gt file: {}\".format(gt_file))\n",
    "\n",
    "        im = cv2.imread(os.path.join(base, ai_mask))\n",
    "        im = cv2.resize(im, (h,w),interpolation=cv2.INTER_NEAREST)\n",
    "        ai_ims.append(im)\n",
    "        imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "        ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "        _, ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #     print(gt_im.shape, im.shape)\n",
    "        if gt_im.sum() == 0: # normal\n",
    "            fppi_cnt += len(ai_contours)\n",
    "\n",
    "        else:\n",
    "            for ai_contour in ai_contours:\n",
    "                _image = np.zeros_like(gt_im)\n",
    "                _image = cv2.drawContours(_image, [ai_contour], 0, color=255, thickness=-1)\n",
    "                if _image[gt_im>0].sum() == 0:\n",
    "                    fppi_cnt += 1\n",
    "    #     print(\"intermediate sum ffpi cnt: {}\".format(fppi_cnt))\n",
    "\n",
    "\n",
    "    if name == 'gugh':\n",
    "        fppi = fppi_cnt/sum_images\n",
    "        print('Calculated FPPI: {}'.format(fppi))\n",
    "\n",
    "        n_bootstraps = 10\n",
    "        rng_seed = 42  # control reproducibility\n",
    "        bootstrapped_scores = []\n",
    "\n",
    "        rng = np.random.RandomState(rng_seed)\n",
    "        for m in range(n_bootstraps):\n",
    "            fppi_cnt = 0\n",
    "\n",
    "        #     y_true = np.ndarray(gt_ims)\n",
    "        #     y_pred = np.ndarray(ai_ims)\n",
    "            ai_li = np.array(ai_li)\n",
    "\n",
    "            # bootstrap by sampling with replacement on the prediction indices\n",
    "            indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "\n",
    "            if len(np.unique(ai_li[indices])) < 2:\n",
    "                # We need at least one positive and one negative sample for ROC AUC\n",
    "                # to be defined: reject the sample\n",
    "                continue\n",
    "                \n",
    "            for name_ci in ai_li[indices]:\n",
    "                \n",
    "                if name_ci.split('-')[0] == 'B':\n",
    "                    hospital_name = 'brmh'\n",
    "                elif name_ci.split('-')[0] == 'K':\n",
    "                    hospital_name = 'kyuh'\n",
    "                elif name_ci.split('-')[0] == 'G':\n",
    "                    hospital_name = 'gugh'\n",
    "                \n",
    "                gt_base = './data/img/result/{}_healthcheck/gt_mask'.format(hospital_name)\n",
    "                base = './data/img/ai_json(all_files)/{}_healthcheck/ai_mask'.format(hospital_name)\n",
    "                \n",
    "                gt_file = '{}_mask.png'.format(name_ci.split('_cutoff')[0])\n",
    "                gt_im = cv2.imread(os.path.join(gt_base, gt_file), cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "                w,h=gt_im.shape\n",
    "\n",
    "                im = cv2.imread(os.path.join(base, name_ci))\n",
    "                im = cv2.resize(im, (h,w),interpolation=cv2.INTER_NEAREST)\n",
    "                imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "                ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
    "                _,ai_contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                if gt_im.sum() == 0: # normal\n",
    "                    fppi_cnt += len(ai_contours)\n",
    "\n",
    "                else:\n",
    "                    for ai_contour in ai_contours:\n",
    "                        _image = np.zeros_like(gt_im)\n",
    "                        _image = cv2.drawContours(_image, [ai_contour], 0, color=255, thickness=-1)\n",
    "                        if _image[gt_im>0].sum() == 0:\n",
    "                            fppi_cnt += 1\n",
    "\n",
    "                score = fppi_cnt/1\n",
    "                bootstrapped_scores.append(score)\n",
    "        #     print(\"Bootstrap #{} ROC area: {:0.3f}\".format(m + 1, score))\n",
    "\n",
    "        sorted_scores = np.array(bootstrapped_scores)\n",
    "        sorted_scores.sort()\n",
    "\n",
    "        # Computing the lower and upper bound of the 90% confidence interval\n",
    "        # You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "        # a 95% confidence interval instead.\n",
    "        confidence_lower = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "        confidence_upper = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "        print(\"FPPI = {:0.4f} [{:0.3f} - {:0.3}]\".format(fppi, confidence_lower/sum_images, confidence_upper/sum_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21450093418185076 0.12070606381169723\n",
      "FPPI = 0.4188 [0.210 - 0.219]\n"
     ]
    }
   ],
   "source": [
    "fppi_score = np.array(fppi_score)\n",
    "mean = fppi_score.mean()\n",
    "std = fppi_score.std()\n",
    "print(mean, std)\n",
    "ci = 1.96*(std/math.sqrt(sum_image))\n",
    "\n",
    "confidence_lower = mean-ci\n",
    "confidence_upper = mean+ci\n",
    "print(\"FPPI = {:0.4f} [{:0.3f} - {:0.3}]\".format(fppi, confidence_lower, confidence_upper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
